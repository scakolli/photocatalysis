{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.drawOptions.addAtomIndices = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchinfo\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal Thread Determination\n",
    "runtimes = []\n",
    "threads = [1] + [t for t in range(2, 49, 2)]\n",
    "num_runs = 5\n",
    "\n",
    "for t in tqdm(threads):\n",
    "    stats_rt = []\n",
    "    for run in range(num_runs):\n",
    "        torch.set_num_threads(t)\n",
    "        r = timeit.timeit(setup = \"import torch; x = torch.randn(1024, 1024); y = torch.randn(1024, 1024)\", stmt=\"torch.mm(x, y)\", number=100)\n",
    "        stats_rt.append(r)\n",
    "    \n",
    "    runtimes.append(np.mean(stats_rt))\n",
    "\n",
    "optimal_num_threads = threads[np.argmin(runtimes)]\n",
    "print('OPTIMAL NUM THREADS:', threads[np.argmin(runtimes)])\n",
    "plt.plot(threads, runtimes)\n",
    "plt.xlabel('Num Threads')\n",
    "plt.ylabel('Run Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ziploc = '/home/btpq/bt308495/Thesis/molecular-vae/data/processed.zip'\n",
    "contentsdest = '/localdisk/bt308495/molecular-vae/data/'\n",
    "\n",
    "### Unzip file to 'contentdest'\n",
    "# with zipfile.ZipFile(ziploc, 'r') as zpf:\n",
    "#     zpf.extractall(contentsdest)\n",
    "\n",
    "### Load data from unzipped file\n",
    "with h5py.File(os.path.join(contentsdest, 'processed.h5'), 'r') as data:\n",
    "    data_train =  data['data_train'][:]\n",
    "    data_test =  data['data_test'][:]\n",
    "    charset =  data['charset'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an additional validation set (80/5/15 train/validate/test split)\n",
    "data_valid, data_test = train_test_split(data_test, test_size=0.75, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape, data_valid.shape, data_test.shape, charset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_smile(onehot_vector, character_set):\n",
    "    ### Take a one-hot vector/tensor (MAX SMILE LENGTH, CHARSET LENGTH) and convert it to a smile string\n",
    "    assert onehot_vector.shape[1] == character_set.size, 'Onehot length doesnt match character_set length'\n",
    "    indicies = np.argmax(onehot_vector, axis=1)\n",
    "    return b''.join(character_set[indicies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_train[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(one_hot_to_smile(data_train[30], charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smis = [one_hot_to_smile(d, charset) for d in data_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.CHARSET_LEN = 33\n",
    "        self.INPUT_SIZE = 120\n",
    "        self.LATENT_DIM = 292\n",
    "\n",
    "        ### ENCODING\n",
    "        # Convolutional Layers\n",
    "        self.conv_1 = nn.Conv1d(self.INPUT_SIZE, 9, kernel_size=9)\n",
    "        self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n",
    "        self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.linear_0 = nn.Linear(70, 435)\n",
    "\n",
    "        # Mean and Variance Latent Layers\n",
    "        self.mean_linear_1 = nn.Linear(435, self.LATENT_DIM)\n",
    "        self.var_linear_2 = nn.Linear(435, self.LATENT_DIM)\n",
    "        \n",
    "        ### DECODING\n",
    "        # Fully connected, GRU RNN, Fully connected layers\n",
    "        # 3 sequential GRUs of hidden size 501. batch_first = True implies batch_dim first. \n",
    "        # Then, inputs into GRU are of shape [batch_size, seq_length (INPUT_SIZE, 120), Hin (LATENT_DIM, 292)]\n",
    "        self.linear_3 = nn.Linear(self.LATENT_DIM, self.LATENT_DIM)\n",
    "        self.stacked_gru = nn.GRU(self.LATENT_DIM, 501, 3, batch_first=True)\n",
    "        self.linear_4 = nn.Linear(501, self.CHARSET_LEN)\n",
    "        \n",
    "        ### ACTIVATION and OUTPUT \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def encode(self, x):\n",
    "        # Convolutional\n",
    "        x = self.relu(self.conv_1(x))\n",
    "        x = self.relu(self.conv_2(x))\n",
    "        x = self.relu(self.conv_3(x))\n",
    "\n",
    "        # Flatten the Convultional output [batch_size, 10, 70] to make an input [batch_size, 10*7] for a fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.selu(self.linear_0(x))\n",
    "\n",
    "        # Mean and logvariance latent vectors [batch_size, latent_dim]\n",
    "        m, v = self.mean_linear_1(x), self.var_linear_2(x) \n",
    "        return m, v\n",
    "\n",
    "    def reparameterize(self, mu_z, logvar_z):\n",
    "        ## Sample a latent vector 'z', given its mean and std vectors\n",
    "        # z ~ N(mu, std), is non-differentiable. While z ~ mu + eps (dot) std, where eps ~ N(0, 1), is differentiable. Why?\n",
    "        # Since mu and std are now deterministic model outputs that can be trained by backprop, while the 'randomness' implicitly enters via the standard normal error/epsilon term\n",
    "        gamma = 1e-2 # not sure why this is here...?\n",
    "        epsilon = gamma * torch.randn_like(logvar_z) # 0 mean, unit variance noise of shape z_logvar\n",
    "        std = torch.exp(0.5 * logvar_z)\n",
    "        z = mu_z + epsilon * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = F.selu(self.linear_3(z))\n",
    "\n",
    "        # Since the GRU, when unrolled in 'time', consists of 120 NNs each sequentially processing data... we have to send 120 copies through it.\n",
    "        # By repeating the tensor z self.INPUT_SIZE times along the sequence length dimension, we are effectively creating a sequence of self.INPUT_SIZE time steps,\n",
    "        # each with the same latent representation. This setup allows the GRU to process this \"sequence\" of repeated tensors, even though the actual sequence content\n",
    "        # is the same at each time step. This kind of setup can be useful for example when:\n",
    "\n",
    "        # 1. Information Propagation: \n",
    "        # Sometimes you want to ensure that a certain piece of information is propagated consistently through the entire sequence. By using repeated tensors, you can\n",
    "        # ensure that the same information is available to the network at every time step, allowing the network to incorporate this information throughout the entire sequence.\n",
    "\n",
    "        # 2. Fixed-Size Context: If you have a fixed-size context or control signal that should influence the processing of the entire sequence, you can repeat this\n",
    "        # context along the sequence length dimension. This way, the network can take into account this context when making decisions at every time step.\n",
    "\n",
    "        # Note on use of contiguous()\n",
    "        # contiguous means 'sharing a common border; touching'\n",
    "        # In the context of pytorch, contiguous means not only contiguous in memory (each element in a tensor is stored right next to the other, in a block),\n",
    "        # but also in the same order in memory as the indices order. For example doing a transposition doesn't change the data in memory (data at (1, 4) doesnt swap\n",
    "        # memory places when its transposed to (4, 1)), it simply changes the map from indices to memory pointers (what index corresponds to what data is swapped instead,\n",
    "        # leaving memory untouched). If you then apply contiguous() it will change the data in memory so that the map from indices to memory location is the canonical one.\n",
    "        # For certain pytorch operations, contiguously stored tensors are required! Else a runtime error is encountered (RuntimeError: input is not contiguous).\n",
    "\n",
    "        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, self.INPUT_SIZE, 1) # Reshape z from [batch_size, latent_dim] to [batch_size, seq_len (120), latent_dim]\n",
    "        output, hs = self.stacked_gru(z) # hs represents the hidden state of the last time step of the GRU\n",
    "\n",
    "        # Output is flattened along 1st two dimensions [batch_size, seq_len, hout] -> [batch_size * seq_len, hout]\n",
    "        # Softmax is then applied row-wise/sample-wise following a linear transform\n",
    "        # before the vector is then unflatten back to the original [batch_size, seq_len, charset_len]\n",
    "\n",
    "        # The purpose of this initial flattening is:\n",
    "        # In the context of a sequence-to-sequence model, each time step's output from the RNN (or a similar sequential model) represents the model's understanding of the\n",
    "        # data at that particular moment. When you collapse the dimensions and reshape the tensor to (batch_size * sequence_length, num_features), you effectively create \n",
    "        # a flat sequence where each element corresponds to a time step's output for a specific sample in the batch.\n",
    "        # Then applying a linear transformation like self.linear_4 at this stage means that the same linear transformation is applied to each element in the flattened sequence\n",
    "        # independently (as if the new batch size is of shape batch_size * seq_len)! This is independent in the sense that the transformation doesn't consider interactions\n",
    "        # between different time steps or different samples within the batch. It's a per-element operation.\n",
    "\n",
    "        # By applying a linear transformation independently to each element, the model has the flexibility to learn different weights for different features at different time steps.\n",
    "        # These weights can capture complex relationships within each time step's output, such as identifying important features or capturing patterns specific to that moment.\n",
    "        # We then reshape back to regain the sequence structure...\n",
    "        out_independent = output.contiguous().view(-1, output.size(-1))\n",
    "        y0 = F.softmax(self.linear_4(out_independent), dim=1)\n",
    "        y = y0.contiguous().view(output.size(0), -1, y0.size(-1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_z, logvar_z = self.encode(x)\n",
    "        z = self.reparameterize(mu_z, logvar_z)\n",
    "        xhat = self.decode(z)\n",
    "        return xhat, mu_z, logvar_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "torchinfo.summary(VAE(), input_size=(batch_size, 120, 33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_z = torch.from_numpy(np.array((np.random.randn(292), np.random.randn(292)))).to(torch.float32)\n",
    "# test_model = VAE()\n",
    "# test_model.decode(test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_tensor[0].size(1)\n",
    "# data_train_tensor[:2].shape, data_train_tensor[:2].view(data_train_tensor[:2].shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_tensor = torch.from_numpy(data_train)\n",
    "data_train_tensor_loader = torch.utils.data.TensorDataset(torch.from_numpy(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the model() on data runs the forward pass through the network\n",
    "VAE()(data_train_tensor[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_loss(x, reconstructed_x_mean, mu_z, logvar_z):\n",
    "    BCE = F.binary_cross_entropy(reconstructed_x_mean, x, reduction='sum') # Pixel-wise reconstruction loss, no-mean taken to match KL-div\n",
    "    KLD = -0.5 * torch.sum(1. + logvar_z - mu_z.pow(2) - logvar_z.exp()) # KL divergence of the latent space distribution\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_tensor = torch.from_numpy(data_train)\n",
    "data_valid_tensor = torch.from_numpy(data_valid)\n",
    "data_test_tensor = torch.from_numpy(data_test)\n",
    "\n",
    "data_train_tensor_loader = torch.utils.data.TensorDataset(data_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(data_train_tensor_loader, batch_size=250, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs = 2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch):\n",
    "    print(f'################ epoch {epoch} ################')\n",
    "    start = time.perf_counter()\n",
    "    model.train() # Tell model we're in train mode, as opposed to eval mode\n",
    "    training_loss, training_bce_loss, training_kld_loss = 0, 0, 0\n",
    "\n",
    "    for batch_indx, X in enumerate(tqdm(train_loader)):\n",
    "        # Reset gradients after each batch and send data to GPU if availables\n",
    "        optimizer.zero_grad()\n",
    "        X = X[0].to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        Xhat, mu_z, logvar_z = model(X)\n",
    "\n",
    "        # Determine Loss, perform backward pass, and update weights\n",
    "        loss, bceloss, kldloss = variational_loss(X, Xhat, mu_z, logvar_z)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        training_bce_loss += bceloss.item()\n",
    "        training_kld_loss += kldloss.item()\n",
    "\n",
    "    # Get model performance on validation set\n",
    "    X_valid = data_valid_tensor.to(device)\n",
    "    Xhat_valid, mu_valid, logvar_valid = model(X_valid)\n",
    "    validation_loss, _, _ = variational_loss(X_valid, Xhat_valid, mu_valid, logvar_valid)\n",
    "\n",
    "    # Summary of training epoch\n",
    "    mean_training_loss = training_loss / len(train_loader.dataset)\n",
    "    mean_training_bce_loss = training_bce_loss / len(train_loader.dataset)\n",
    "    mean_training_kld_loss = training_kld_loss / len(train_loader.dataset)\n",
    "    mean_validation_loss = validation_loss.item() / data_valid_tensor.shape[0]\n",
    "\n",
    "    test_points = X[0].cpu(), Xhat[0].cpu().detach() # Access a datapoint, send to cpu, and remove gradient\n",
    "    test_smiles = [one_hot_to_smile(t.numpy(), charset) for t in test_points]\n",
    "\n",
    "    print(f'Epoch took: {(time.perf_counter() - start) / 60.} mins')\n",
    "    print('Mean Training Loss:', mean_training_loss)\n",
    "    print('Mean Validation Loss:', mean_validation_loss)\n",
    "    print('---------------------')\n",
    "    print('Sampled Input, Ouput Smiles:')\n",
    "    _ = [print(t) for t in test_smiles]\n",
    "    \n",
    "    return (mean_training_loss, mean_training_bce_loss, mean_training_kld_loss), mean_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls, vls = [], []\n",
    "for epoch in range(1, epochs+1):\n",
    "    training_losses, validation_loss = train_epoch(epoch)\n",
    "    tls.append(training_losses), vls.append(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('VAE_losses.pckl', 'wb') as f:\n",
    "#     pickle.dump([tls, vls], f)\n",
    "\n",
    "with open('VAE_losses.pckl', 'rb') as f:\n",
    "    tls, vls = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model params\n",
    "PATH = 'test_model.pt'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# Load model\n",
    "# model = VAE()\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# # model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_epoch(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "PATH = '/home/btpq/bt308495/Thesis/VAE_model_parmas.pt'\n",
    "model = VAE()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "with open('/home/btpq/bt308495/Thesis/VAE_losses.pckl', 'rb') as f:\n",
    "    tls, vls = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = np.array(tls)\n",
    "vls = np.array(vls)\n",
    "\n",
    "train_loss, bce_loss, kld_loss = tls[:, 0], tls[:, 1], tls[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_loss, color='blue', label='Train')\n",
    "plt.plot(range(len(vls)), vls, color='green', label='Validate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(bce_loss)), bce_loss, color='red', label='BCE')\n",
    "plt.plot(range(len(kld_loss)), kld_loss, color='purple', label='KLD')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Broken Down Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how model performs on test smiles\n",
    "Xhat_test, mu_test, logvar_test = model(data_test_tensor)\n",
    "test_loss, _, _ = variational_loss(data_test_tensor, Xhat_test, mu_test, logvar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training loss (proxy):', train_loss[-1])\n",
    "print('Validation loss (proxy):', vls[-1])\n",
    "print('Test loss:', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
