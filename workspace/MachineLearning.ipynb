{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS']='32'\n",
    "# os.environ['MKL_NUM_THREADS']='32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "from ase.units import Hartree\n",
    "from ase.visualize import view\n",
    "\n",
    "from ase.io.trajectory import Trajectory\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.drawOptions.addAtomIndices = True\n",
    "\n",
    "from photocatalysis.learners_treesearch import get_population_completed\n",
    "from photocatalysis.learners_treesearch import generate_ml_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For automatically reloading import modules... allows you to run changes to code in jupyter without having to reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOCAL\n",
    "# local_path = os.path.join('/home/scakolli/Thesis/photocatalysis/workspace', 'DF_COMPLETE.json')\n",
    "# df = pd.read_json(local_path, orient='split')\n",
    "\n",
    "### REMOTE\n",
    "df = pd.read_json('/home/btpq/bt308495/Thesis/frames/DF_COMPLETE.json', orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fizzled / Total\")\n",
    "print(\"{} / {}\".format(df.loc[df.calc_status == 'fizzled'].shape[0], df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get succesfully completed\n",
    "df = get_population_completed(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragment Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Fragments\n",
    "rdkit_fragments = [f for f in dir(Fragments) if 'fr_' in f]\n",
    "\n",
    "def GetFragmentFingerprint(smile):\n",
    "    # Create a 86 bit vector that indicates whether one of the canonical RDKIT fragments is present in the molecule\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    bits = [getattr(Fragments, frag_func)(mol) for frag_func in rdkit_fragments]\n",
    "    return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = []\n",
    "for i, row in df.iterrows():\n",
    "    fps.append(GetFragmentFingerprint(row.molecule_smiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adsorbate Configuration Descriptors\n",
    "\n",
    "Need to adapt GPR Model for multiple dimensions.... might use GPFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import regex\n",
    "import ast\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "from photocatalysis.adsorption.tools import build_configuration_from_site\n",
    "from osc_discovery.cheminformatics.cheminformatics_misc import rdkit2ase\n",
    "from photocatalysis.adsorption.helpers import ase2rdkit_valencies, get_neighboring_bonds_list\n",
    "from photocatalysis.adsorption.constants import OH, O, OOH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_activesite(d):\n",
    "    pattern = r'\\[(?:[^[\\]]+|(?R))*\\]'\n",
    "    matches = regex.findall(pattern, d)\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_activesite_from_file(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = f.read().decode('UTF-8').splitlines()\n",
    "\n",
    "        asites = []\n",
    "        for d in data:\n",
    "            smi = d.split(' ')[0]\n",
    "            d_new = d.replace(smi, '')\n",
    "            asites_tmp = ast.literal_eval(parse_activesite(d_new))\n",
    "            asites.append((smi, asites_tmp))\n",
    "        \n",
    "    return asites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['/home/btpq/bt308495/Thesis/run/learner_results_0to4096/molecules_to_calculate_results/results_calculations.txt',\n",
    "         '/home/btpq/bt308495/Thesis/run/learner_results_Batch1/molecules_to_calculate_results/results_calculations.txt',\n",
    "         '/home/btpq/bt308495/Thesis/run/learner_results_Batch2/molecules_to_calculate_results/results_calculations.txt',\n",
    "         '/home/btpq/bt308495/Thesis/run/learner_results_Batch3/molecules_to_calculate_results/results_calculations.txt',\n",
    "         '/home/btpq/bt308495/Thesis/run/learner_results_Batch4/molecules_to_calculate_results/results_calculations.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_asites = []\n",
    "for file in files:\n",
    "    tot_asites += parse_activesite_from_file(file)\n",
    "\n",
    "for i, (_, ts) in enumerate(tot_asites):\n",
    "    for j, t in enumerate(ts):\n",
    "        if isinstance(t, str):\n",
    "            tot_asites[i][1][j] = ast.literal_eval(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['active_sites'] = df['molecule_smiles'].map(dict(tot_asites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.iloc[3374]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adsorbate_fingerprints(smile, active_sites):\n",
    "    # Smile string, 3 active sites\n",
    "\n",
    "    mol = Chem.AddHs(Chem.MolFromSmiles(smile))\n",
    "    AllChem.EmbedMolecule(mol)\n",
    "    ase_mol = rdkit2ase(mol)\n",
    "    ase_mol.info['bonds'] = get_neighboring_bonds_list(ase_mol)\n",
    "\n",
    "    fps = []\n",
    "    for i, ads in enumerate([OH, O, OOH]):\n",
    "        asites = active_sites[i]\n",
    "        config = build_configuration_from_site(ads, ase_mol, asites)[0]\n",
    "        rdkit_mol = ase2rdkit_valencies(config, removeHs=True)\n",
    "        fp = AllChem.GetMorganFingerprint(rdkit_mol, 2)\n",
    "        fps.append(fp)\n",
    "\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = deepcopy(df)\n",
    "errors = []\n",
    "for j, row in tqdm(df_copy.iterrows()):\n",
    "    if not isinstance(row.active_sites, float):\n",
    "        try:\n",
    "            fingerprints = adsorbate_fingerprints(row.molecule_smiles, row.active_sites)\n",
    "            for col, f in zip(['OH', 'O', 'OOH'], fingerprints):\n",
    "                df_copy.at[j, col] = f\n",
    "        except Exception as e:\n",
    "            print(j, e)\n",
    "            errors.append((j, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_copy = deepcopy(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adsorb_fingerprint = deepcopy(df_copy_copy[~df_copy_copy.OH.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/btpq/bt308495/Thesis/frames/DF_COMPLETE_AFP.pckl', 'wb') as f:\n",
    "#     pickle.dump(df_adsorb_fingerprint, f)\n",
    "\n",
    "with open('/home/btpq/bt308495/Thesis/frames/DF_COMPLETE_AFP.pckl', 'rb') as f:\n",
    "    df_adsorb_fingerprint = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photocatalysis.learners_treesearch import ML_model, generate_ml_vectors\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, r2_score, PredictionErrorDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data and OPTIMIZED model parameters\n",
    "scratch_dir = '/localdisk/bt308495/'\n",
    "scratch_fname = 'scratch_distance_matrix_70_30'\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, 'ML_IP_70_30.pckl'), 'rb') as f:\n",
    "    df_training, df_test, kip = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, 'ML_dGmax_70_30.pckl'), 'rb') as f:\n",
    "    _, _, krdg = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gather test data\n",
    "df_test = generate_ml_vectors(df_test)\n",
    "\n",
    "X_test = df_test.morgan_fp_bitvect.values\n",
    "y_test_ip = df_test.IP.values\n",
    "y_test_rdg = df_test.dGmax.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train/fit Models given params (~ 2 x 5min)\n",
    "gpr_ip = ML_model(df_training, 'IP', kip, multiprocess=16, D_scratch_dir=os.path.join(scratch_dir, scratch_fname))\n",
    "gpr_rdg = ML_model(df_training, 'dGmax', krdg, multiprocess=16, D_scratch_dir=os.path.join(scratch_dir, scratch_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing models\n",
    "ip_gpr_fname = 'gpr_ip.pckl'\n",
    "rdg_gpr_fname = 'gpr_dGmax.pckl'\n",
    "\n",
    "## Save Models\n",
    "# with open(os.path.join(scratch_dir, scratch_fname, ip_gpr_fname), 'wb') as f:\n",
    "#     pickle.dump(gpr_ip, f)\n",
    "\n",
    "# with open(os.path.join(scratch_dir, scratch_fname, rdg_gpr_fname), 'wb') as f:\n",
    "#     pickle.dump(gpr_rdg, f)\n",
    "\n",
    "### Load models\n",
    "with open(os.path.join(scratch_dir, scratch_fname, ip_gpr_fname), 'rb') as f:\n",
    "    gpr_ip = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, rdg_gpr_fname), 'rb') as f:\n",
    "    gpr_rdg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred_ip, std_test_pred_ip = gpr_ip.predict(X_test, return_std=True) **** SLOW (70mins)\n",
    "y_test_pred_ip = gpr_ip.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred_rdg, std_test_pred_rdg = gpr_rdg.predict(X_test, return_std=True) **** SLOW (70mins)\n",
    "y_test_pred_rdg = gpr_rdg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(scratch_dir, scratch_fname, 'y_pred_shuffled.pckl'), 'wb') as f:\n",
    "#     pickle.dump([y_test_pred_ip, y_test_pred_rdg], f)\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, 'y_pred_shuffled.pckl'), 'rb') as f:\n",
    "    y_test_pred_ip, y_test_pred_rdg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['IP_pred'] = y_test_pred_ip\n",
    "df_test['dGmax_pred'] = y_test_pred_rdg\n",
    "df_test['utility_function_pred'] = df_test['IP_pred'] - df_test['dGmax_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Metrics\n",
    "mae_ip = mean_absolute_error(y_test_ip, y_test_pred_ip) # mae\n",
    "r2_ip = r2_score(y_test_ip, y_test_pred_ip) # pearson r2 score\n",
    "# evs_ip = explained_variance_score(y_test_ip, y_test_pred_ip) # explained variance\n",
    "\n",
    "mae_rdg = mean_absolute_error(y_test_rdg, y_test_pred_rdg) # mae\n",
    "r2_rdg = r2_score(y_test_rdg, y_test_pred_rdg) # pearson r2 score\n",
    "# evs_rdg = explained_variance_score(y_test_rdg, y_test_pred_rdg) # explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals and performance\n",
    "r_ip = abs(y_test_ip - y_test_pred_ip)\n",
    "r_rdg = abs(y_test_rdg - y_test_pred_rdg)\n",
    "\n",
    "ranked_r_ip = np.sort(r_ip)\n",
    "ranked_r_rdg = np.sort(r_rdg)\n",
    "\n",
    "thresh = 0.1\n",
    "f_over_ip, f_over_rdg = 100*np.sum(r_ip < thresh) / r_ip.size, 100*np.sum(r_rdg < thresh) / r_rdg.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "label_ip = f'r\\u00b2 = {round(r2_ip, 2)} \\nMAE = {round(mae_ip, 3)} eV'\n",
    "ax[0].scatter(y_test_ip, y_test_pred_ip, label=label_ip, alpha=0.7)\n",
    "ax[0].plot(y_test_ip, y_test_ip, 'k')\n",
    "ax[0].set_xlabel('True')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "ax[0].set_title('IP')\n",
    "ax[0].legend()\n",
    "\n",
    "label_rdg = f'r\\u00b2 = {round(r2_rdg, 2)} \\nMAE = {round(mae_rdg, 3)} eV'\n",
    "ax[1].scatter(y_test_rdg, y_test_pred_rdg, label=label_rdg, alpha=0.7, c='green')\n",
    "ax[1].plot(y_test_rdg, y_test_rdg, 'k')\n",
    "ax[1].set_xlabel('True')\n",
    "ax[1].set_ylabel('Predicted')\n",
    "ax[1].set_title('dGmax')\n",
    "ax[1].legend()\n",
    "\n",
    "fig.tight_layout(pad=1.0)\n",
    "text = fig.text(0.50, -0.1, \n",
    "                f'SHUFFLED 70/30 split \\nTraining Set: {df_training.shape[0]} mols, Test Set: {df_test.shape[0]} mols \\nPredicted within 0.1 eV of True   |   IP : {round(f_over_ip, 1)} %, dGmax : {round(f_over_rdg, 1)} %', \n",
    "                horizontalalignment='center', wrap=True )\n",
    "\n",
    "# fig.suptitle(f'GPR Model fit to {df_training.shape[0]} mols, tested on {df_test.shape[0]} mols (70/30 split)') #, fontsize=20)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(y_test_ip, y_test_pred_ip, label='IP', alpha=0.7)\n",
    "# ax.plot(y_test_ip, y_test_ip, 'k')\n",
    "# ax.set_xlabel('True')\n",
    "# ax.set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = np.load('/localdisk/bt308495/D.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title('Normalized model uncertainty, $\\sigma / \\sigma_{population}$ ')\n",
    "# plt.hist(std_test_pred_ip/np.nanstd(df_test.IP.values), label='IP', density=True, bins=20)\n",
    "# # plt.hist(stdrdg/np.nanstd(main_frame.dGmax.values), label='dGmax', density=True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Shuffled (Mimicking AL setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data and OPTIMIZED model parameters\n",
    "scratch_dir = '/localdisk/bt308495/'\n",
    "scratch_fname = 'scratch_distance_matrix_70_30_NoShuffle'\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, 'ML_IP.pckl'), 'rb') as f:\n",
    "    ndf_training, ndf_test, nkip = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, 'ML_dGmax.pckl'), 'rb') as f:\n",
    "    _, _, nkrdg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gather test data\n",
    "ndf_test = generate_ml_vectors(ndf_test)\n",
    "\n",
    "nX_test = ndf_test.morgan_fp_bitvect.values\n",
    "ny_test_ip = ndf_test.IP.values\n",
    "ny_test_rdg = ndf_test.dGmax.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train/fit Models given params (~ 2 x 5min)\n",
    "ngpr_ip = ML_model(ndf_training, 'IP', nkip, multiprocess=16, D_scratch_dir=os.path.join(scratch_dir, scratch_fname))\n",
    "ngpr_rdg = ML_model(ndf_training, 'dGmax', nkrdg, multiprocess=16, D_scratch_dir=os.path.join(scratch_dir, scratch_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storing models\n",
    "nip_gpr_fname = 'gpr_ip.pckl'\n",
    "nrdg_gpr_fname = 'gpr_dGmax.pckl'\n",
    "\n",
    "# Save Models\n",
    "# with open(os.path.join(scratch_dir, scratch_fname, nip_gpr_fname), 'wb') as f:\n",
    "#     pickle.dump(ngpr_ip, f)\n",
    "\n",
    "# with open(os.path.join(scratch_dir, scratch_fname, nrdg_gpr_fname), 'wb') as f:\n",
    "#     pickle.dump(ngpr_rdg, f)\n",
    "\n",
    "### Load models\n",
    "with open(os.path.join(scratch_dir, scratch_fname, nip_gpr_fname), 'rb') as f:\n",
    "    ngpr_ip = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, nrdg_gpr_fname), 'rb') as f:\n",
    "    ngpr_rdg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ny_test_pred_ip, nstd_test_pred_ip = ngpr_ip.predict(nX_test, return_std=True) **** SLOW (70mins)\n",
    "ny_test_pred_ip = ngpr_ip.predict(nX_test)\n",
    "\n",
    "# ny_test_pred_rdg, nstd_test_pred_rdg = ngpr_rdg.predict(nX_test, return_std=True) **** SLOW (70mins)\n",
    "ny_test_pred_rdg = ngpr_rdg.predict(nX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(scratch_dir, scratch_fname, 'y_pred_nonshuffled.pckl'), 'wb') as f:\n",
    "#     pickle.dump([ny_test_pred_ip, ny_test_pred_rdg], f)\n",
    "\n",
    "with open(os.path.join(scratch_dir, scratch_fname, 'y_pred_nonshuffled.pckl'), 'rb') as f:\n",
    "    ny_test_pred_ip, ny_test_pred_rdg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Metrics\n",
    "nmae_ip = mean_absolute_error(ny_test_ip, ny_test_pred_ip) # mae\n",
    "nr2_ip = r2_score(ny_test_ip, ny_test_pred_ip) # pearson r2 score\n",
    "# nevs_ip = explained_variance_score(ny_test_ip, ny_test_pred_ip) # explained variance\n",
    "\n",
    "nmae_rdg = mean_absolute_error(ny_test_rdg, ny_test_pred_rdg) # mae\n",
    "nr2_rdg = r2_score(ny_test_rdg, ny_test_pred_rdg) # pearson r2 score\n",
    "# nevs_rdg = explained_variance_score(ny_test_rdg, ny_test_pred_rdg) # explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals and performance\n",
    "nr_ip = abs(ny_test_ip - ny_test_pred_ip)\n",
    "nr_rdg = abs(ny_test_rdg - ny_test_pred_rdg)\n",
    "\n",
    "nranked_r_ip = np.sort(nr_ip)\n",
    "nranked_r_rdg = np.sort(nr_rdg)\n",
    "\n",
    "nthresh = 0.1\n",
    "nf_over_ip, nf_over_rdg = 100*np.sum(nr_ip < nthresh) / nr_ip.size, 100*np.sum(nr_rdg < nthresh) / nr_rdg.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "nlabel_ip = f'r\\u00b2 = {round(nr2_ip, 2)} \\nMAE = {round(nmae_ip, 3)} eV'\n",
    "ax[0].scatter(ny_test_ip, ny_test_pred_ip, label=nlabel_ip, alpha=0.7)\n",
    "ax[0].plot(ny_test_ip, ny_test_ip, 'k')\n",
    "ax[0].set_xlabel('True')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "ax[0].set_title('IP')\n",
    "ax[0].legend()\n",
    "\n",
    "nlabel_rdg = f'r\\u00b2 = {round(nr2_rdg, 2)} \\nMAE = {round(nmae_rdg, 3)} eV'\n",
    "ax[1].scatter(ny_test_rdg, ny_test_pred_rdg, label=nlabel_rdg, alpha=0.7, c='green')\n",
    "ax[1].plot(ny_test_rdg, ny_test_rdg, 'k')\n",
    "ax[1].set_xlabel('True')\n",
    "ax[1].set_ylabel('Predicted')\n",
    "ax[1].set_title('dGmax')\n",
    "ax[1].legend()\n",
    "\n",
    "fig.tight_layout(pad=1.0)\n",
    "text = fig.text(0.50, -0.1, \n",
    "                f'UN-SHUFFLED 70/30 split (Mimicks AL setting) \\nTraining Set: {ndf_training.shape[0]} mols, Test Set: {ndf_test.shape[0]} mols \\nPredicted within 0.1 eV of True   |   IP : {round(nf_over_ip, 1)} %, dGmax : {round(nf_over_rdg, 1)} %', \n",
    "                horizontalalignment='center', wrap=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, HTML\n",
    "# display(Image(filename='/home/btpq/bt308495/Thesis/IP_dGmax_Fit_Shuffled.png'))\n",
    "\n",
    "image_path1 = '/home/btpq/bt308495/Thesis/IP_dGmax_Fit_Shuffled.png'\n",
    "image_path2 = '/home/btpq/bt308495/Thesis/IP_dGmax_Fit_UnShuffled.png'\n",
    "\n",
    "\n",
    "HTML(f\"\"\"\n",
    "    <div class=\"row\">\n",
    "            <img src={image_path1} style=\"width:40%\"> </img>\n",
    "            <img src={image_path2} style=\"width:40%\"> </img>\n",
    "    </div>\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf_test['IP_pred'] = ny_test_pred_ip\n",
    "ndf_test['dGmax_pred'] = ny_test_pred_rdg\n",
    "ndf_test['utility_function_pred'] = ndf_test['IP_pred'] - ndf_test['dGmax_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(gen, d.shape[0]) for gen, d in df.groupby('generation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid = (2, 4)\n",
    "cmap = get_cmap(len(ndf_test.generation.unique()), name='viridis')\n",
    "fig, ax = plt.subplots(*plt_grid, figsize=[8.5, 8.5])\n",
    "fig.suptitle('IP | Predicted vs True across generations')\n",
    "ms_ip, rs_ip = [], []\n",
    "\n",
    "for i, (gen, d) in enumerate(ndf_test.groupby('generation')):\n",
    "    mae_gen = mean_absolute_error(d.IP, d.IP_pred) # mae\n",
    "    r2_gen = r2_score(d.IP, d.IP_pred) # pearson r2 score\n",
    "    ms_ip.append(mae_gen), rs_ip.append(r2_gen)\n",
    "\n",
    "    label_gen = f'r\\u00b2={round(r2_gen, 2)} \\nMAE={round(mae_gen, 2)}eV'\n",
    "    indx = np.unravel_index(i, plt_grid)\n",
    "    ax[indx].set_title(f'Gen {gen}')\n",
    "    ax[indx].scatter(ndf_test.IP, ndf_test.IP_pred, alpha=0.1, c='gray')\n",
    "    ax[indx].scatter(d.IP, d.IP_pred, c=cmap(i), alpha=0.7, label=label_gen)\n",
    "    ax[indx].plot(ndf_test.IP, ndf_test.IP, 'k')\n",
    "    ax[indx].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid = (2, 4)\n",
    "cmap = get_cmap(len(ndf_test.generation.unique()), name='viridis')\n",
    "fig, ax = plt.subplots(*plt_grid, figsize=[8.5, 8.5])\n",
    "fig.suptitle('dGmax | Predicted vs True across generations')\n",
    "ms_rdg, rs_rdg = [], []\n",
    "\n",
    "for i, (gen, d) in enumerate(ndf_test.groupby('generation')):\n",
    "    mae_gen = mean_absolute_error(d.dGmax, d.dGmax_pred) # mae\n",
    "    r2_gen = r2_score(d.dGmax, d.dGmax_pred) # pearson r2 score\n",
    "    ms_rdg.append(mae_gen), rs_rdg.append(r2_gen)\n",
    "\n",
    "    label_gen = f'r\\u00b2={round(r2_gen, 2)} \\nMAE={round(mae_gen, 2)}eV'\n",
    "    indx = np.unravel_index(i, plt_grid)\n",
    "    ax[indx].set_title(f'Gen {gen}')\n",
    "    ax[indx].scatter(ndf_test.dGmax, ndf_test.dGmax_pred, alpha=0.1, c='gray')\n",
    "    ax[indx].scatter(d.dGmax, d.dGmax_pred, c=cmap(i), alpha=0.7, label=label_gen)\n",
    "    ax[indx].plot(ndf_test.dGmax, ndf_test.dGmax, 'k')\n",
    "    ax[indx].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of Gen 7 in training data:')\n",
    "print(round(100*(1 - ndf_test.loc[ndf_test.generation == 7].shape[0] / df.loc[df.generation == 7].shape[0]), 1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens = ndf_test.generation.unique()\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].plot(gens, ms_ip, label='IP')\n",
    "ax[0].plot(gens, ms_rdg, c='green', label='dGmax')\n",
    "ax[0].set_xlabel('Generation')\n",
    "ax[0].set_ylabel('MAE (eV)')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(gens, rs_ip, label='IP')\n",
    "ax[1].plot(gens, rs_rdg, c='green', label='dGmax')\n",
    "ax[1].set_xlabel('Generation')\n",
    "ax[1].set_ylabel('r\\u00b2')\n",
    "ax[1].legend()\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "fig.suptitle('Metrics vs Generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_gen_dftest = deepcopy(ndf_test.loc[ndf_test.generation > 7, ['IP', 'dGmax', 'IP_pred', 'dGmax_pred', 'utility_function', 'utility_function_pred']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "r2_ip_o = r2_score(out_of_gen_dftest.IP, out_of_gen_dftest.IP_pred)\n",
    "mae_ip_o = mean_absolute_error(out_of_gen_dftest.IP, out_of_gen_dftest.IP_pred)\n",
    "\n",
    "r2_dGmax_o = r2_score(out_of_gen_dftest.dGmax, out_of_gen_dftest.dGmax_pred)\n",
    "mae_dGmax_o = mean_absolute_error(out_of_gen_dftest.dGmax, out_of_gen_dftest.dGmax_pred)\n",
    "\n",
    "nlabel_ip = f'r\\u00b2 = {round(r2_ip_o, 2)} \\nMAE = {round(mae_ip_o, 3)} eV'\n",
    "ax[0].scatter(out_of_gen_dftest.IP, out_of_gen_dftest.IP_pred, label=nlabel_ip, alpha=0.7)\n",
    "ax[0].plot(out_of_gen_dftest.IP, out_of_gen_dftest.IP, 'k')\n",
    "ax[0].set_xlabel('True')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "ax[0].set_title('IP')\n",
    "ax[0].legend()\n",
    "\n",
    "nlabel_ip = f'r\\u00b2 = {round(r2_dGmax_o, 2)} \\nMAE = {round(mae_dGmax_o, 3)} eV'\n",
    "ax[1].scatter(out_of_gen_dftest.dGmax, out_of_gen_dftest.dGmax_pred, label=nlabel_ip, alpha=0.7, c='green')\n",
    "ax[1].plot(out_of_gen_dftest.dGmax, out_of_gen_dftest.dGmax, 'k')\n",
    "ax[1].set_xlabel('True')\n",
    "ax[1].set_ylabel('Predicted')\n",
    "ax[1].set_title('dGmax')\n",
    "ax[1].legend()\n",
    "\n",
    "# nlabel_rdg = f'r\\u00b2 = {round(nr2_rdg, 2)} \\nMAE = {round(nmae_rdg, 3)} eV'\n",
    "# ax[1].scatter(ny_test_rdg, ny_test_pred_rdg, label=nlabel_rdg, alpha=0.7, c='green')\n",
    "# ax[1].plot(ny_test_rdg, ny_test_rdg, 'k')\n",
    "# ax[1].set_xlabel('True')\n",
    "# ax[1].set_ylabel('Predicted')\n",
    "# ax[1].set_title('dGmax')\n",
    "# ax[1].legend()\n",
    "\n",
    "fig.tight_layout(pad=1.0)\n",
    "text = fig.text(0.50, -0.1, \n",
    "                f'Strictly out of Generation prediction \\nTraining Set: Up to Gen 7, Test Set: Gen 8 and above \\nPredicted within 0.1 eV of True   |   IP : {round(nf_over_ip, 1)} %, dGmax : {round(nf_over_rdg, 1)} %', \n",
    "                horizontalalignment='center', wrap=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=[11, 7])\n",
    "\n",
    "r21 = r2_score(ndf_test.utility_function, ndf_test.utility_function_pred)\n",
    "mae1 = mean_absolute_error(ndf_test.utility_function, ndf_test.utility_function_pred)\n",
    "\n",
    "r22 = r2_score(out_of_gen_dftest.utility_function, out_of_gen_dftest.utility_function_pred)\n",
    "mae2 = mean_absolute_error(out_of_gen_dftest.utility_function, out_of_gen_dftest.utility_function_pred)\n",
    "\n",
    "ndf_test_7 = deepcopy(ndf_test.loc[ndf_test.generation == 7])\n",
    "r23 = r2_score(ndf_test_7.utility_function, ndf_test_7.utility_function_pred)\n",
    "mae3 = mean_absolute_error(ndf_test_7.utility_function, ndf_test_7.utility_function_pred)\n",
    "\n",
    "nlabel = f'r\\u00b2 = {round(r2_ip, 2)} \\nMAE = {round(mae_ip, 3)} eV'\n",
    "ax[0].scatter(df_test.utility_function, df_test.utility_function_pred, label=nlabel, alpha=0.7, c='blue')\n",
    "ax[0].plot(df.utility_function, df.utility_function, 'k')\n",
    "ax[0].set_xlabel('True')\n",
    "ax[0].set_ylabel('Predicted Utility, IP - dGmax (eV)')\n",
    "ax[0].set_title('Shuffled')\n",
    "ax[0].legend()\n",
    "\n",
    "nlabel = f'r\\u00b2 = {round(r21, 2)} \\nMAE = {round(mae1, 3)} eV'\n",
    "ax[1].scatter(ndf_test.utility_function, ndf_test.utility_function_pred, label=nlabel, alpha=0.7, c='red')\n",
    "ax[1].plot(df.utility_function, df.utility_function, 'k')\n",
    "ax[1].set_xlabel('True')\n",
    "# ax[1].set_ylabel('Predicted')\n",
    "ax[1].set_title('Un-shuffled')\n",
    "ax[1].legend()\n",
    "\n",
    "nlabel_s = f'r\\u00b2 = {round(r22, 2)} \\nMAE = {round(mae2, 3)} eV'\n",
    "ax[2].scatter(out_of_gen_dftest.utility_function, out_of_gen_dftest.utility_function_pred, label=nlabel_s, alpha=0.7, c='orange')\n",
    "ax[2].plot(df.utility_function, df.utility_function, 'k')\n",
    "ax[2].set_xlabel('True')\n",
    "# ax[2].set_ylabel('Predicted')\n",
    "ax[2].set_title('Out of Generation')\n",
    "ax[2].legend()\n",
    "\n",
    "nlabel_s = f'r\\u00b2 = {round(r23, 2)} \\nMAE = {round(mae3, 3)} eV'\n",
    "ax[3].scatter(ndf_test_7.utility_function, ndf_test_7.utility_function_pred, label=nlabel_s, alpha=0.7, c='purple')\n",
    "ax[3].plot(df.utility_function, df.utility_function, 'k')\n",
    "ax[3].set_xlabel('True')\n",
    "# ax[3].set_ylabel('Predicted')\n",
    "ax[3].set_title('Within of Generation \\ngen 7, 25/75 split')\n",
    "ax[3].legend()\n",
    "\n",
    "fig.tight_layout(pad=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "1. Model is pretty good\n",
    "2. Its even better when its trained on samples from the same generation as the test case (of course...)\n",
    "3. When enough data is present, IP is modelled more accurately than dGmax\n",
    "4. Perhaps we can modify the AL algorithm to make it more robust:\n",
    "At iteration 6 in the learning process, we produce generation 7, and we subsequently try to predict gen-7 properties using a model that is trained on molecules from gen-6 and below. Perhaps instead, at iteration 6, we can add some random gen-7 molecules to the training set, and use that model to predict the rest of the gen-7 properties.\n",
    "\n",
    "### TODO\n",
    "1. Data mining to uncover structure-property relationships\n",
    "2. Perhaps this can motivate new morphing operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting GPR using gpr_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photocatalysis.learners_treesearch import generate_ml_vectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.linalg import cholesky, cho_solve, solve_triangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_ml_vectors(df)\n",
    "df_training, df_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = df_training.morgan_fp_bitvect.values\n",
    "y_train = df_training.IP.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "_y_train_mean = np.mean(y_train, axis=0)\n",
    "_y_train_std = np.std(y_train, axis=0)\n",
    "y_train = (y_train - _y_train_mean) / _y_train_std\n",
    "y_train = np.array(y_train, ndmin=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_params = {'C':1., 'length_scale':1., 'sigma_n':0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1m3s (16 core)\n",
    "#### 59s (42 core)\n",
    "# Load distance matrix\n",
    "D = np.load('/localdisk/bt308495/scratch_distance_matrix_80_20/D_mat.npy')\n",
    "\n",
    "# construct kernel with noise\n",
    "white_noise = np.eye(len(X_train),len(X_train)) * kernel_params['sigma_n']**2\n",
    "K = kernel_params['C']**2*(1.-D)\n",
    "K += white_noise\n",
    "\n",
    "# Cholesky decomposition\n",
    "L = cholesky(K, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1m28s (16 core)\n",
    "### 1m5s (42 core)\n",
    "alpha = cho_solve((L, True), y_train)\n",
    "L_inv = solve_triangular(L.T, np.eye(L.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/localdisk/bt308495/D.npy', D)\n",
    "# np.save('/localdisk/bt308495/K.npy', K)\n",
    "# np.save('/localdisk/bt308495/L.npy', L)\n",
    "# np.save('/localdisk/bt308495/L_inv.npy', L_inv)\n",
    "\n",
    "D = np.load('/localdisk/bt308495/D.npy')\n",
    "K = np.load('/localdisk/bt308495/K.npy')\n",
    "L = np.load('/localdisk/bt308495/L.npy')\n",
    "L_inv = np.load('/localdisk/bt308495/L_inv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = cho_solve((L, True), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_gradient = np.dstack(( (np.full((K.shape[0], K.shape[1]), 2*kernel_params['C'],\n",
    "                            dtype=np.array(kernel_params['C']).dtype)*K)[:, :, np.newaxis],\n",
    "                           ( kernel_params['C']**2* np.zeros(K.shape) )[:, :, np.newaxis], \n",
    "                           (np.eye(len(X_train), len(X_train)) * 2*kernel_params['sigma_n'])[:, :, np.newaxis]\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1m53s (32 core)\n",
    "### 1m45.7 (42 core)\n",
    "L_inv_T = L_inv.copy().T\n",
    "K_inv = L_inv.dot(L_inv_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Log Marginal Likehood determination')\n",
    "log_likelihood_dims = -0.5 * np.einsum(\"ik,ik->k\", y_train, alpha)\n",
    "log_likelihood_dims -= np.log(np.diag(L)).sum()\n",
    "log_likelihood_dims -= len(X_train) / 2 * np.log(2 * np.pi)\n",
    "log_likelihood = log_likelihood_dims.sum(-1)  # sum over dimensions\n",
    "\n",
    "\n",
    "tmp = np.einsum(\"ik,jk->ijk\", alpha, alpha)  # k: output-dimension\n",
    "tmp -= cho_solve((L, True), np.eye(len(X_train)))[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_gradient_dims = 0.5 * np.einsum(\"ijl,jik->kl\", tmp, K_gradient)\n",
    "log_likelihood_gradient = log_likelihood_gradient_dims.sum(-1)\n",
    "output = float(log_likelihood), log_likelihood_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.95\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photocatalysis.learners_treesearch import generate_ml_vectors, get_ML_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With np.arrays()\n",
    "# X = generate_ml_vectors(df).morgan_fp_bitvect.values\n",
    "\n",
    "# Y_IP = df.IP.values\n",
    "# Y_dGmax = df.dGmax.values\n",
    "\n",
    "# X_train_IP, X_test_IP, y_train_IP, y_test_IP = train_test_split(X, Y_IP, test_size=test_size, random_state=random_state)\n",
    "# X_train_dGmax, X_test_dGmax, y_train_dGmax, y_test_dGmax = train_test_split(X, Y_dGmax, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With pd.DataFrames()\n",
    "df_training, df_test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "df_test = generate_ml_vectors(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y='utility_function', kind='hist', bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "gpr_ip, xtrain_ip, kip = get_ML_model(df_training, 'IP', multiprocess=1, D_scratch_dir='/run/user/1308495/scratch_distance_matrix', niter_local=1)\n",
    "print('IP Fitting Took:', time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_scratch = '/run/user/1308495'\n",
    "save_path = os.path.join(main_scratch, 'ML_IP_95_1.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path, 'wb') as p:\n",
    "    pickle.dump([gpr_ip, xtrain_ip, kip], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path, 'rb') as p:\n",
    "    out = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.morgan_fp_bitvect.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yip, stdip = gpr_ip.predict(X_test, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "gpr_rdg, xtrain_rdg, krdg = get_ML_model(df_training, 'dGmax', multiprocess=1, D_scratch_dir='/run/user/1308495/scratch_distance_matrix', niter_local=1)\n",
    "print('RDG Fitting Took:', time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
