{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "from photocatalysis.learners_treesearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For automatically reloading import modules... allows you to run changes to code in jupyter without having to reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in dataframe of testspaces\n",
    "base = '/home/btpq/bt308495/Thesis/'\n",
    "path = '/home/btpq/bt308495/Thesis/osc_discovery/data/'\n",
    "run_dir = '/home/btpq/bt308495/Thesis/run'\n",
    "# reference = pd.read_json(path+'df_chemical_space_chons_4rings.json', orient='split')\n",
    "# limited = pd.read_json(path+'df_initial_gfn1_testspace.json', orient='split') #limited testspace, gfn1\n",
    "# unlimited = pd.read_json(path+'df_initial_b3lyp_unlimited.json', orient='split') #unlimited testspace, b3lyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a small custom test-space for troubleshooting/experimenting\n",
    "# limited[['XTB1_lamda_h', 'ehomo_gfn1_b3lyp']] = np.nan * np.ones((limited.shape[0], 2))\n",
    "Ntest = 4\n",
    "testspace = limited[1:Ntest+1].copy().drop(columns=['XTB1_lamda_h', 'ehomo_gfn1_b3lyp']) #no benzene\n",
    "testspace.insert(5, 'IP', np.nan)\n",
    "testspace.insert(6, 'dGmax', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = pd.read_json('/home/btpq/bt308495/Thesis/run/initialized_testspace/df_population.json', orient='split')\n",
    "# frame.loc[frame.calc_status == 'fizzled', 'calc_status'] = 'not written'\n",
    "# frame.to_json('/home/btpq/bt308495/Thesis/run/df_incomplete_intialized.json', orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ initialized completed frame\n",
    "# main_frame = pd.read_json('/home/btpq/bt308495/Thesis/df_initial_gfn1_testspace_photocatalysis.json', orient='split')\n",
    "main_frame = pd.read_json('/home/btpq/bt308495/Thesis/run/df_population_runstep5.json', orient='split')\n",
    "training_frame = main_frame.loc[main_frame.added_in_round <= 2]\n",
    "test_frame = main_frame.loc[main_frame.added_in_round > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mip, mrdg = [], []\n",
    "rips, rrdgs = [], []\n",
    "for round_added in range(main_frame.added_in_round.min(), main_frame.added_in_round.max()):\n",
    "    print('Learning Step:', round_added)\n",
    "    training_frame = main_frame.loc[main_frame.added_in_round <= round_added]\n",
    "    test_frame = main_frame.loc[main_frame.added_in_round > round_added]\n",
    "    test_frame_uniq = get_unique_population(get_population_completed(test_frame))\n",
    "\n",
    "    # Get test data\n",
    "    Xtest = generate_ml_vectors(test_frame_uniq).morgan_fp_bitvect.values\n",
    "\n",
    "    # Fit Model on training data\n",
    "    gpr_ip, _, _ = get_ML_model(training_frame, 'IP')\n",
    "    gpr_rdg, _, _ = get_ML_model(training_frame, 'dGmax')\n",
    "\n",
    "    # Predict on test data\n",
    "    yip_true = test_frame_uniq.IP.values\n",
    "    yrdg_true = test_frame_uniq.dGmax.values\n",
    "\n",
    "    yip, stdip = gpr_ip.predict(Xtest, return_std=True)\n",
    "    yrdg, stdrdg = gpr_rdg.predict(Xtest, return_std=True)\n",
    "\n",
    "    # Evaluate Performace\n",
    "    mad_ip = mean_absolute_error(yip_true, yip) # MAD\n",
    "    mad_rdg = mean_absolute_error(yrdg_true, yrdg)\n",
    "\n",
    "    rip = yip_true - yip # residuals\n",
    "    rrdg = yrdg_true - yrdg\n",
    "    \n",
    "    # store\n",
    "    mip.append(mad_ip), mrdg.append(mad_rdg), rips.append(rip), rrdgs.append(rrdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mip)\n",
    "plt.plot(mrdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "for j, (r0, r1) in enumerate(zip(rips, rrdgs)):\n",
    "    ax[0].hist(r0, label=j, density=True, alpha=0.5)\n",
    "    ax[1].hist(r1, label=j, density=True, alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame.loc[main_frame.added_in_round==1].utility_function.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_utility_by_round = [df.utility_function.median() for j, df in main_frame.groupby('added_in_round')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_utility_by_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on initial set\n",
    "gpr_ip, _, _ = get_ML_model(training_frame, 'IP')\n",
    "gpr_rdg, _, _ = get_ML_model(training_frame, 'dGmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame_uniq = get_unique_population(get_population_completed(test_frame))\n",
    "Xtest = generate_ml_vectors(test_frame_uniq).morgan_fp_bitvect.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predicting\n",
    "yip, stdip = gpr_ip.predict(Xtest, return_std=True)\n",
    "yrdg, stdrdg = gpr_rdg.predict(Xtest, return_std=True)\n",
    "\n",
    "# Real\n",
    "yip_true, yrdg_true = test_frame_uniq.IP.values, test_frame_uniq.dGmax.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_ip = mean_absolute_error(yip_true, yip)\n",
    "mad_rdg = mean_absolute_error(yrdg_true, yrdg)\n",
    "print('Mean Abs Errors:',mad_ip, mad_rdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rip = yip_true - yip\n",
    "rrdg = yrdg_true - yrdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rip)\n",
    "plt.hist(rrdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "plt.scatter(yip_true, yip)\n",
    "plt.scatter(yip_true, yip_true, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(yrdg_true, yrdg)\n",
    "plt.scatter(yrdg_true, yrdg_true, c='r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Children\n",
    "main_frame.loc[main_frame.calc_status == 'fizzled', 'molecule_smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = active_learner(df_initial_population=main_frame, **AL_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIT GPR to initial frame\n",
    "gpr_ip, xtrain_ip = al._get_ML_model('IP')\n",
    "gpr_rdg, xtrain_rdg = al._get_ML_model('dGmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPR predictions\n",
    "yip, stdip = gpr_ip.predict(xtrain_ip, return_std=True)\n",
    "yrdg, stdrdg = gpr_rdg.predict(xtrain_rdg, return_std=True)\n",
    "\n",
    "# Ground truth labels\n",
    "yip_true = al.df_population_unique[al.df_population_unique.calc_status == 'completed'].IP.values\n",
    "yrdg_true = al.df_population_unique[al.df_population_unique.calc_status == 'completed'].dGmax.values\n",
    "\n",
    "mad_training_ip = np.sqrt(((yip_true-yip)**2).sum())\n",
    "mad_training_rdg = np.sqrt(((yrdg_true-yrdg)**2).sum())\n",
    "\n",
    "print('Perfect fit to training data, as expected')\n",
    "print(mad_training_ip, mad_training_rdg)\n",
    "\n",
    "print('Limited Variance near training points, as expected')\n",
    "print(stdip.max(), stdrdg.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial Candidates predicted to water split:', np.sum((yip - yrdg) > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_candidates = al.select_and_add_new_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_candidates = al._generate_ml_vectors(df_new_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = df_new_candidates.morgan_fp_bitvect.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yip, stdip = gpr_ip.predict(Xtest, return_std=True)\n",
    "yrdg, stdrdg = gpr_rdg.predict(Xtest, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yip - yrdg, bins=20)\n",
    "plt.title('Utility Hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated Candidates predicted to water split:', np.sum((yip - yrdg) > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(stdip, bins=20, label='IP')\n",
    "plt.hist(stdrdg, bins=20, label='RDG')\n",
    "plt.title('Stdevs Hist')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = al._get_utility(np.stack((yip, yrdg)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production Run (use_reference_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other args with default values\n",
    "# kappa = 2.5 # regarding two-fold in article\n",
    "# n_batch = 100 # candidates to selct at every step\n",
    "# two_fold = 0 # if 1, two-time application of morphing ops at each step used\n",
    "# use_reference_frame = 1 # Gfn1 limited testspace\n",
    "# n_learning_steps = 50\n",
    "# suffix = '' # Namespace\n",
    "# random_state = 42\n",
    "# reduced_search_space = 0 # 1 for turning on search space reduction.. not sure what this means yet\n",
    "# depth_search = 3 # d_search as discussed in the artice\n",
    "# Ndeep = 500 # N_deep as discussed in article\n",
    "\n",
    "# # This is the evaluation in a predefined chemical space, without dft evaluation\n",
    "\n",
    "# # initial generation dataframe, contains mols and descriptors, already contains B3LYP corrected xTB-GFN1\n",
    "# df_initial_population = pd.read_json(path+'df_initial_gfn1_testspace.json', orient='split')\n",
    "# df_reference = pd.read_json(path+'df_chemical_space_chons_4rings.json', orient='split') #reference frame\n",
    "\n",
    "# preset_chemical_space_boundaries = \"test_osc_space\"\n",
    "# n_worker_submit = 1 # How many workers to submit\n",
    "# n_select_every_step = n_batch\n",
    "# n_execute_every_step = 0 # 0 means all cases are always found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Args into active_learner_run\n",
    "properties=[\"IP\", \"dGmax\"]\n",
    "\n",
    "# Worker-HPC stuff (local, not computing cluster)\n",
    "run_mode = 'local'\n",
    "# worker_submit_file = 'submit_local.sh'\n",
    "worker_submit_file = '/home/btpq/bt308495/Thesis/worker/worker_xtb.py'\n",
    "\n",
    "system = 'ARTHUR'\n",
    "dir_scratch = '/home/btpq/bt308495/Thesis/scratch/'\n",
    "submit_command = 'qsub'\n",
    "queue_status_command = 'qstat'\n",
    "\n",
    "dir_save_results = 'learner_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space defining settings\n",
    "df_reference=[]\n",
    "# df_initial_population = testspace.copy()\n",
    "preset_chemical_space_boundaries = '' # unlimited\n",
    "preset_chemical_space_boundaries = 'test_osc_space' # limited size of molecules to 4rings, etc. Space comprises of 65,552 mols\n",
    "\n",
    "# Search space reduction setttings\n",
    "reduced_search_space = 0 # 1 for reduction\n",
    "depth_search = 3 # reduced space setting\n",
    "Ndeep = 500 # Reduced search space setting\n",
    "\n",
    "# Learner Settings\n",
    "kappa = 0 #Exploitative, 2.5 offers a better balance between exploitation and exploration\n",
    "two_fold = 0\n",
    "n_learning_steps = 10\n",
    "n_select_every_step = 50 # N_batch_first: queries per learning step; choose the Nbatch best Fitness mols and proceed expansion with them\n",
    "n_execute_every_step = 0 # HPC to avoid idles times #int(args.n_batch) # 0 means all cases are always found before proceeding to next step\n",
    "\n",
    "# Misc settings\n",
    "n_worker_submit = 1 #8 for HPC... need SLURM\n",
    "random_state = 42\n",
    "suffix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unique molecules generated by exhaustively performing all molecular morphing operations\n",
    "### 65,552 Molecules\n",
    "# df_reference.copy().drop_duplicates(subset='molecule_smiles').shape\n",
    "\n",
    "### Initialization population\n",
    "# df_initial_population.copy().drop_duplicates(subset='molecule_smiles').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_step(active_learner_obj, run_only=False):\n",
    "    while True:\n",
    "        if active_learner_obj.check_all_calculations_finished():\n",
    "            print('Finished calculations... moving on')\n",
    "            print('###############')\n",
    "            break\n",
    "        else:\n",
    "            print('Running Calculations')\n",
    "            active_learner_obj.run_calculations_population()\n",
    "            print('###############')\n",
    "\n",
    "    if not run_only:\n",
    "        active_learner_obj.select_and_add_new_candidates()\n",
    "        active_learner_obj.run_calculations_population()\n",
    "    print('###############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_params = {'properties' : properties,\n",
    "            'n_worker_submit' : n_worker_submit,\n",
    "            'Nbatch_first' : n_select_every_step,\n",
    "            'Nbatch_finish_successful' : n_execute_every_step,\n",
    "            'run_mode' : run_mode, \n",
    "            'worker_submit_file' : worker_submit_file,\n",
    "            'submit_command' : submit_command,\n",
    "            'queue_status_command' : queue_status_command,\n",
    "            'two_generations_search' : two_fold,\n",
    "            'df_reference_chemical_space' : [], #reference, \n",
    "            'kappa' : kappa, \n",
    "            'reduced_search_space' : reduced_search_space,\n",
    "            'depth_search' : depth_search,\n",
    "            'Ndeep' : Ndeep,\n",
    "            'preset' : preset_chemical_space_boundaries,\n",
    "            'dir_save_results' : dir_save_results,\n",
    "            'dir_scratch' : dir_scratch,\n",
    "            'ml_model' : 'gpr_tanimoto_kernel',\n",
    "            'random_state' : int(random_state),\n",
    "            'suffix' : suffix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(run_dir), os.getcwd()\n",
    "AL = active_learner(df_initial_population=testspace.copy(), **AL_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_step(AL, run_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gapr, xtrain = tal._get_ML_model('IP')\n",
    "# xtests = tal._generate_ml_vectors(limited.copy())['morgan_fp_bitvect'].values\n",
    "# out = gapr.predict(xtests, return_std=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/btpq/bt308495/Thesis/run/AL_pickled.pckl', 'wb') as pick:\n",
    "#     pickle.dump(AL, pick)\n",
    "\n",
    "# with open('/home/btpq/bt308495/Thesis/run/AL_pickled.pckl', 'rb') as pick:\n",
    "#     al = pickle.load(pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AL.check_all_calculations_finished():\n",
    "    print('All Calcs Performed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL.select_and_add_new_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL.evaluate_performance_external_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = AL.df_reference_chemical_space_unique[AL.properties].values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = AL._predict_Fi_scores(AL.df_population_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL._get_utility(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL.df_reference_chemical_space_unique['utility_function']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
